{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOHablVe64ucdnHmeBJORqV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/annasugian/Sugian_ML_course/blob/main/ML_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Базовый уровень: Генерация текста с использованием LSTM\n",
        "0. Сбор данных: используйте готовый или соберите свой корпус в формате plain text для генерации текстов\n",
        "\n",
        "1. Генерация текста на основе небольшого датасета\n",
        "\n",
        "- Предварительный анализ: чистка текста\n",
        "- Обучение модели. Используйте образец из туториала по RNNи\n",
        "- Генерация текста. Используйте образец из туториала по RNN\n",
        "- Сгенерируйте несколько текстов с помощью созданной модели\n",
        "\n",
        "## Подготовка датасета: Чистка текста\n",
        "Текст - 3 романа из серии Джорджа Мартина \"Песнь льда и пламени\". Сложно было понять, нужно ли оставлять какие-то знаки препинания, напр. вопросительные, или кавычки, ведь это важно для художественной литературы. Но я решила все же оставить только точки."
      ],
      "metadata": {
        "id": "ookMTo0xsvS7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R51VL_LHmTRS",
        "outputId": "4ab8e5f9-b0c7-481f-c9de-07451fa4573d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['we have a long ride before us gared pointed out',\n",
              " ' eight days maybe nine',\n",
              " ' and night is falling',\n",
              " ' ser waymar royce glanced at the sky with disinterest',\n",
              " ' it does that every day about this time',\n",
              " ' are you unmanned by the dark gared will could see the tightness around gareds mouth the barely sup pressed anger in his eyes under the thick black hood of his cloak',\n",
              " ' gared had spent forty years in the nights watch man and boy and he was not accustomed to being made light of',\n",
              " ' yet it was more than that',\n",
              " ' under the wounded pride will could sense something else in the older man',\n",
              " ' you could taste it a nervous tension that came perilous close to fear',\n",
              " ' will shared his unease',\n",
              " ' he had been four years on the wall',\n",
              " ' the first time he had been sent beyond all the old stories had come rushing back and his bowels had turned to water',\n",
              " ' he had laughed about it afterward',\n",
              " ' he was a veteran of a hundred rangings by now and the endless dark wilderness that the southron called the haunted forest had no more terrors for him',\n",
              " ' until tonight',\n",
              " ' something was different tonight',\n",
              " ' there was an edge to this darkness that made his hackles rise',\n",
              " ' nine days they had been riding north and northwest and then north again farther and farther from the wall hard on the track of a band of wildling raiders',\n",
              " ' each day had been worse than the day that had come before it']"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "output_file = 'Song_of_Ice_and_Fire.txt'\n",
        "input_files = ['1 - A Game of Thrones.txt', '2 - A Clash of Kings.txt', '3 - A Storm of Swords.txt']\n",
        "\n",
        "with open(output_file, 'w', encoding='ISO-8859-1') as outfile:\n",
        "    for filename in input_files:\n",
        "        with open(filename, 'r', encoding='ISO-8859-1') as infile:\n",
        "            outfile.write(infile.read())\n",
        "\n",
        "\n",
        "with open('Song_of_Ice_and_Fire.txt', 'r', encoding='ISO-8859-1') as f:\n",
        "    text = f.read()\n",
        "\n",
        "pattern = r'\\s*Page\\s*\\d+\\s*|[^\\w\\s.]|\\n(?=\\w)'\n",
        "cleanedtext = re.sub(pattern, '', text.lower()).strip()\n",
        "\n",
        "with open('Clean_SoIaF.txt', 'w', encoding='utf-8') as f:\n",
        "    f.write(cleanedtext)\n",
        "\n",
        "with open('Clean_SoIaF.txt', 'r', encoding='utf-8') as f:\n",
        "    data = f.read()\n",
        "\n",
        "data = data.split('.')\n",
        "data[:20]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Данные пришлось сильно убавить, так как колаб не справлялся"
      ],
      "metadata": {
        "id": "S62NwYhHu_hg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = data[:10000]"
      ],
      "metadata": {
        "id": "0X0KzTV3mgZP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "cii65ACImi2Z"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Инициализируем токенизатор\n",
        "tokenizer = Tokenizer()\n",
        "\n",
        "# Обучаем токенизатор на заголовках\n",
        "tokenizer.fit_on_texts(data)\n",
        "\n",
        "# Преобразуем заголовки в последовательности чисел\n",
        "sequences = tokenizer.texts_to_sequences(data)\n",
        "\n",
        "# Создаем входные и выходные данные\n",
        "X = []\n",
        "y = []\n",
        "for seq in sequences:\n",
        "    for i in range(1, len(seq)):\n",
        "        X.append(seq[:i])\n",
        "        y.append(seq[i])"
      ],
      "metadata": {
        "id": "fInW3Bg0mk_r"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Вопрос: Какие значения попадают в y, а что хранится в X'ах?\n",
        "\n",
        "В Х хранятся входные данные. Это последовательность нарастающей длины, \"история\" токенов. Х подается на вход нейросети как контекст.\n",
        "\n",
        "В у хранятся целевые значения. Это следующий токен после текущей последовательности из Х. у это то, что модель должна предсказать на каждом шаге"
      ],
      "metadata": {
        "id": "957-7md8vFhV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X[:10], y[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKQBlLVimoYA",
        "outputId": "b65b65d2-ea17-477a-a7f2-c44e09e59b18"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([[81],\n",
              "  [81, 34],\n",
              "  [81, 34, 3],\n",
              "  [81, 34, 3, 101],\n",
              "  [81, 34, 3, 101, 272],\n",
              "  [81, 34, 3, 101, 272, 99],\n",
              "  [81, 34, 3, 101, 272, 99, 151],\n",
              "  [81, 34, 3, 101, 272, 99, 151, 537],\n",
              "  [81, 34, 3, 101, 272, 99, 151, 537, 823],\n",
              "  [951]],\n",
              " [34, 3, 101, 272, 99, 151, 537, 823, 55, 350])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Преобразуем списки в массивы numpy\n",
        "X = np.asarray(X, dtype=\"object\")\n",
        "y = np.array(y)\n",
        "\n",
        "# Дополняем последовательности до одинаковой длины\n",
        "X = pad_sequences(X)\n",
        "\n",
        "# Преобразуем y в one-hot encoding\n",
        "y = tf.keras.utils.to_categorical(y, num_classes=len(tokenizer.word_index) + 1)"
      ],
      "metadata": {
        "id": "YAPg7LcLmqiK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Создание и обучение модели"
      ],
      "metadata": {
        "id": "vYLBVeZb3t5l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Создаем модель\n",
        "model = Sequential()\n",
        "\n",
        "# Добавляем слой Embedding\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100, input_length=X.shape[1]))\n",
        "\n",
        "# Добавляем слой LSTM\n",
        "model.add(LSTM(150, return_sequences=False))\n",
        "\n",
        "# Добавляем полносвязный слой\n",
        "model.add(Dense(len(tokenizer.word_index) + 1, activation='softmax'))\n",
        "\n",
        "# Компилируем модель\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Выводим информацию о модели\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "id": "OTyR-E7Smwsc",
        "outputId": "26aa7a72-3296-4311-833d-d2fb74765d0d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Обучаем модель\n",
        "history = model.fit(X, y, epochs=40, batch_size=64, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SjJFdVImyma",
        "outputId": "950110d1-c7e2-4dfd-97b7-9929a77ab793"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.0568 - loss: 6.9139 - val_accuracy: 0.0866 - val_loss: 6.5235\n",
            "Epoch 2/40\n",
            "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 13ms/step - accuracy: 0.0992 - loss: 5.9696 - val_accuracy: 0.1059 - val_loss: 6.2882\n",
            "Epoch 3/40\n",
            "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.1247 - loss: 5.5261 - val_accuracy: 0.1182 - val_loss: 6.2296\n",
            "Epoch 4/40\n",
            "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.1422 - loss: 5.1808 - val_accuracy: 0.1238 - val_loss: 6.2386\n",
            "Epoch 5/40\n",
            "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 13ms/step - accuracy: 0.1531 - loss: 4.9392 - val_accuracy: 0.1259 - val_loss: 6.2908\n",
            "Epoch 6/40\n",
            "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 13ms/step - accuracy: 0.1680 - loss: 4.6966 - val_accuracy: 0.1264 - val_loss: 6.3863\n",
            "Epoch 7/40\n",
            "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.1814 - loss: 4.4759 - val_accuracy: 0.1282 - val_loss: 6.4820\n",
            "Epoch 8/40\n",
            "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.1937 - loss: 4.2773 - val_accuracy: 0.1274 - val_loss: 6.6107\n",
            "Epoch 9/40\n",
            "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.2115 - loss: 4.0679 - val_accuracy: 0.1283 - val_loss: 6.7422\n",
            "Epoch 10/40\n",
            "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.2326 - loss: 3.8768 - val_accuracy: 0.1279 - val_loss: 6.8865\n",
            "Epoch 11/40\n",
            "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.2546 - loss: 3.7160 - val_accuracy: 0.1264 - val_loss: 7.0348\n",
            "Epoch 12/40\n",
            "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 13ms/step - accuracy: 0.2804 - loss: 3.5345 - val_accuracy: 0.1231 - val_loss: 7.1741\n",
            "Epoch 13/40\n",
            "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 13ms/step - accuracy: 0.3038 - loss: 3.3862 - val_accuracy: 0.1234 - val_loss: 7.3144\n",
            "Epoch 14/40\n",
            "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.3303 - loss: 3.2348 - val_accuracy: 0.1210 - val_loss: 7.4469\n",
            "Epoch 15/40\n",
            "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 13ms/step - accuracy: 0.3486 - loss: 3.1101 - val_accuracy: 0.1190 - val_loss: 7.5887\n",
            "Epoch 16/40\n",
            "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.3733 - loss: 2.9834 - val_accuracy: 0.1204 - val_loss: 7.7069\n",
            "Epoch 17/40\n",
            "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.3934 - loss: 2.8603 - val_accuracy: 0.1165 - val_loss: 7.8423\n",
            "Epoch 18/40\n",
            "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.4151 - loss: 2.7420 - val_accuracy: 0.1132 - val_loss: 7.9659\n",
            "Epoch 19/40\n",
            "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.4339 - loss: 2.6483 - val_accuracy: 0.1151 - val_loss: 8.0932\n",
            "Epoch 20/40\n",
            "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.4515 - loss: 2.5471 - val_accuracy: 0.1114 - val_loss: 8.2158\n",
            "Epoch 21/40\n",
            "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.4739 - loss: 2.4414 - val_accuracy: 0.1106 - val_loss: 8.3292\n",
            "Epoch 22/40\n",
            "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 13ms/step - accuracy: 0.4950 - loss: 2.3426 - val_accuracy: 0.1101 - val_loss: 8.4538\n",
            "Epoch 23/40\n",
            "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.5082 - loss: 2.2674 - val_accuracy: 0.1072 - val_loss: 8.5704\n",
            "Epoch 24/40\n",
            "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 13ms/step - accuracy: 0.5273 - loss: 2.1936 - val_accuracy: 0.1061 - val_loss: 8.6963\n",
            "Epoch 25/40\n",
            "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5416 - loss: 2.1055 - val_accuracy: 0.1048 - val_loss: 8.8314\n",
            "Epoch 26/40\n",
            "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5586 - loss: 2.0376 - val_accuracy: 0.1053 - val_loss: 8.9310\n",
            "Epoch 27/40\n",
            "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.5708 - loss: 1.9717 - val_accuracy: 0.1011 - val_loss: 9.0380\n",
            "Epoch 28/40\n",
            "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 13ms/step - accuracy: 0.5828 - loss: 1.9115 - val_accuracy: 0.1031 - val_loss: 9.1576\n",
            "Epoch 29/40\n",
            "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 13ms/step - accuracy: 0.5958 - loss: 1.8510 - val_accuracy: 0.1006 - val_loss: 9.2861\n",
            "Epoch 30/40\n",
            "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.6100 - loss: 1.7894 - val_accuracy: 0.0999 - val_loss: 9.3798\n",
            "Epoch 31/40\n",
            "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.6204 - loss: 1.7343 - val_accuracy: 0.0983 - val_loss: 9.5090\n",
            "Epoch 32/40\n",
            "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 13ms/step - accuracy: 0.6318 - loss: 1.6788 - val_accuracy: 0.0966 - val_loss: 9.6075\n",
            "Epoch 33/40\n",
            "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 13ms/step - accuracy: 0.6443 - loss: 1.6234 - val_accuracy: 0.0988 - val_loss: 9.7100\n",
            "Epoch 34/40\n",
            "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.6558 - loss: 1.5837 - val_accuracy: 0.0981 - val_loss: 9.7944\n",
            "Epoch 35/40\n",
            "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.6631 - loss: 1.5413 - val_accuracy: 0.0958 - val_loss: 9.9277\n",
            "Epoch 36/40\n",
            "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 13ms/step - accuracy: 0.6739 - loss: 1.4874 - val_accuracy: 0.0957 - val_loss: 10.0360\n",
            "Epoch 37/40\n",
            "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.6822 - loss: 1.4504 - val_accuracy: 0.0978 - val_loss: 10.1590\n",
            "Epoch 38/40\n",
            "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.6917 - loss: 1.4064 - val_accuracy: 0.0951 - val_loss: 10.2574\n",
            "Epoch 39/40\n",
            "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 13ms/step - accuracy: 0.6994 - loss: 1.3720 - val_accuracy: 0.0943 - val_loss: 10.3420\n",
            "Epoch 40/40\n",
            "\u001b[1m1364/1364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 13ms/step - accuracy: 0.7112 - loss: 1.3269 - val_accuracy: 0.0943 - val_loss: 10.4585\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "eR1MCzPym2vD",
        "outputId": "57709257-2752-4ce9-f973-b27417916379"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m105\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │         \u001b[38;5;34m819,200\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)                 │         \u001b[38;5;34m150,600\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8192\u001b[0m)                │       \u001b[38;5;34m1,236,992\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">105</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">819,200</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">150,600</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8192</span>)                │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,236,992</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,620,378\u001b[0m (25.25 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,620,378</span> (25.25 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,206,792\u001b[0m (8.42 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,206,792</span> (8.42 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m4,413,586\u001b[0m (16.84 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,413,586</span> (16.84 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Посмотрим на то, как модель генерирует тексты"
      ],
      "metadata": {
        "id": "k-ZFZlYUuWDW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция для генерации текста\n",
        "def generate_text(seed_text, next_words, max_sequence_len):\n",
        "    for _ in range(next_words):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "        predicted = np.argmax(model.predict(token_list), axis=-1)\n",
        "\n",
        "        output_word = \"\"\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == predicted:\n",
        "                output_word = word\n",
        "                break\n",
        "        seed_text += \" \" + output_word\n",
        "    return seed_text\n",
        "\n",
        "# Генерируем новый текст\n",
        "generated_text = generate_text(\"Winter\", 30, X.shape[1])\n",
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yvwALlgm3RW",
        "outputId": "b9691be7-8bbb-4363-c970-657b22f14840"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "Winter is coming from us for him either now i know jaimes dark sin and the magister bowed slightly my lord husband gave her a world to his face a grey\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Должно было быть скорее так:\n",
        "*Winter is coming <s>from us</s> for him. Either now i know, <u>jaime's</u> <u>a</u> dark sin<u>nner</u>. <s>and</s> The magister bowed slightly. \"My lord husband gave her a world\" <u>she said</u> to his face that was <s>a</s> grey*"
      ],
      "metadata": {
        "id": "usqae-HbtHOY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Попробуем сгенерировать еще несколько текстов\n",
        "generated_text = generate_text(\"Lannister\", 10, X.shape[1])\n",
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpchdHj5wqAh",
        "outputId": "150fd7e7-17e0-4baf-f94f-77a4c513210d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Lannister mocks us leave us in a rock and the other\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generated_text = generate_text(\"Sister\", 10, X.shape[1])\n",
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e9apU78w1Xb",
        "outputId": "996da398-2046-4b3c-cda5-b78142a79384"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "Sister we will fight their names in the river and argue\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Сохраняем модель\n",
        "model.save('GoT_generator.keras')"
      ],
      "metadata": {
        "id": "RB9_kXXLuTJO"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Статья: https://papers.neurips.cc/paper_files/paper/2016/file/16026d60ff9b54410b3435b403afd226-Paper.pdf\n",
        "\n",
        "- Чем этот подход отличается от Teacher Forcing?\n",
        "\n",
        "Teacher Forcing – обучение с учителем (подача эталонных данных на вход). А Professor Forcing – адаптивное состязательное выравнивание динамики.\n",
        "- Опишите основной принцип предложенного в статье подхода.\n",
        "\n",
        "Professor Forcing применяет метод адаптации доменов с использованием состязательного обучения, чтобы динамика рекуррентной сети оставалась одинаковой как во время обучения, так и при генерации последовательностей на множестве шагов.\n",
        "- Какие недостатки есть у подхода Professor Forcing?\n",
        "\n",
        "Для данного подхода нужно намного больше вычислительных ресурсов. Авторы отмечают, что метод улучшает генерацию аудио, несмотря на <u>короткие</u> обучающие последовательности. Однако это может быть не универсальным: для других задач (например, текста) преимущества могут быть менее выражены.\n",
        "\n",
        "Статья про LSTM: https://ieeexplore.ieee.org/document/8690387\n",
        "\n",
        "Статья про GRU: https://arxiv.org/abs/1406.1078\n",
        "\n",
        "- Опишите основной принцип работы этих моделей\n",
        "\n",
        "Обе модели используют механизмы вентилей (gates), которые регулируют поток информации, но делают это немного по-разному. LSTM вводит три ключевых вентиля (forget, input, output), а GRU два (reset, update). LSTM поддерживает долговременную память и кратковременную - две переменные. GRU объединяет долговременную и кратковременную память в одно состояние - одна переменная.\n",
        "Обе модели решают главную проблему RNN — забывание информации на больших дистанциях, но делают это разными способами.\n",
        "\n",
        "- Что такое гейты и как они помогают избежать типичных проблем RNN?\n",
        "\n",
        "Гейты — это специализированные механизмы в LSTM и GRU, которые регулируют поток информации с помощью сигмоидных и гиперболических тангенсов функций. Они открываются или закрываются для сохранения полезной информации, забывания ненужной и обновления. Каждый гейт выдаёт значение от 0 (полное блокирование) до 1 (полное пропускание).\n",
        "\n",
        "У RNN две главные проблемы: исчезающие градиенты, взрывающиеся градиенты и долгосрочная зависимость.\n",
        "Гейт забывания (Forget Gate в LSTM) контролирует, какие данные сохранить в долговременной памяти. Если информация важна, гейт оставляет её почти нетронутой, предотвращая \"затухание\" градиентов.\n",
        "Skip-connections позволяют градиентам течь без затухания через многие временные шаги.\n",
        "Гейты ограничивают масштаб изменений, и функции активации также держат значения в диапазоне [-1, 1], предотвращая неконтролируемый рост.\n",
        "Вентиль обновления (Update Gate) в GRU решает, сколько прошлой информации сохранить, а сколько заменить новой, балансируя между кратко- и долгосрочной памятью.\n",
        "\n",
        "- Насколько надежно использование LSTM / GRU против взрывающегося / исчезающего градиента?\n",
        "\n",
        "LSTM и GRU не полностью устраняют проблемы градиентов, но делают их менее критичными. LSTM надёжнее для экстремально длинных зависимостей. GRU — хороший компромисс для большинства задач."
      ],
      "metadata": {
        "id": "tx5QXr8hwWPN"
      }
    }
  ]
}